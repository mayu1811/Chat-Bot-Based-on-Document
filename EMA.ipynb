{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cCgJkZwTMSNz"
      },
      "outputs": [],
      "source": [
        "!pip install langchain sentence_transformers -q\n",
        "!pip install chromadb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "6aR7OSI9N650",
        "outputId": "a375798c-e826-40c1-c5d5-6ace880d32ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-generativeai==0.5.0\n",
            "  Downloading google_generativeai-0.5.0-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-ai-generativelanguage==0.6.1 (from google-generativeai==0.5.0)\n",
            "  Downloading google_ai_generativelanguage-0.6.1-py3-none-any.whl (663 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.6/663.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.0) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.0) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.0) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.0) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.0) (2.7.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.0) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.5.0) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.1->google-generativeai==0.5.0) (1.23.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.5.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.5.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.5.0) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.5.0) (1.63.1)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.5.0) (2.31.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.5.0) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.5.0) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.5.0) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai==0.5.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai==0.5.0) (2.18.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.5.0) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.5.0) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai==0.5.0) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.5.0) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.5.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.5.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.5.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.5.0) (2024.6.2)\n",
            "Installing collected packages: google-ai-generativelanguage, google-generativeai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.4\n",
            "    Uninstalling google-ai-generativelanguage-0.6.4:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.4\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.5.4\n",
            "    Uninstalling google-generativeai-0.5.4:\n",
            "      Successfully uninstalled google-generativeai-0.5.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 1.0.3 requires google-generativeai<0.6.0,>=0.5.2, but you have google-generativeai 0.5.0 which is incompatible.\n",
            "langchain-google-genai 1.0.3 requires langchain-core<0.2,>=0.1.45, but you have langchain-core 0.2.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.1 google-generativeai-0.5.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "1370559973ff4a439e2c0ca40ed3fccd",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install google-generativeai==0.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By1QEX2bN7lM",
        "outputId": "96f2f67a-e212-4eab-8dba-dd40e391ec0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-google-genai==1.0.3\n",
            "  Downloading langchain_google_genai-1.0.3-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai==1.0.3) (0.5.4)\n",
            "Collecting langchain-core<0.2,>=0.1.45 (from langchain-google-genai==1.0.3)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (2.7.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (1.23.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai==1.0.3) (6.0.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2,>=0.1.45->langchain-google-genai==1.0.3)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2,>=0.1.45->langchain-google-genai==1.0.3)\n",
            "  Using cached langsmith-0.1.81-py3-none-any.whl (127 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.45->langchain-google-genai==1.0.3)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain-google-genai==1.0.3) (8.4.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (4.9)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.45->langchain-google-genai==1.0.3)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai==1.0.3)\n",
            "  Using cached orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai==1.0.3) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (2.18.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (1.63.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai==1.0.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai==1.0.3) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai==1.0.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain-google-genai==1.0.3) (2024.6.2)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-google-genai\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.1.52 langchain-google-genai-1.0.3 langsmith-0.1.81 orjson-3.10.5 packaging-23.2\n"
          ]
        }
      ],
      "source": [
        " pip install langchain-google-genai==1.0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iFxZ-UhDOA_6"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pQYvswkOplv",
        "outputId": "188eb55b-5653-42df-8e99-8eee947e5718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m174.1/232.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU59ziLtUBr7",
        "outputId": "c6967a41-cb94-4279-a375-153deddae267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install unstructured -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z_6WR4UUaAs",
        "outputId": "f07c8018-bfcb-4822-e7a5-a6612becee3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.5)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.9)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.81)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain-community) (2.7.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain-community) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain-community) (2.18.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Installing collected packages: langchain-community\n",
            "Successfully installed langchain-community-0.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r_0IvzJDUvYk",
        "outputId": "3687c25f-0735-42a7-8474-4c117b84e562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unstructured[pdf] in /usr/local/lib/python3.10/dist-packages (0.14.7)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.12.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.6.7)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2024.4.27)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.25.2)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.9.3)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.12.2)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.23.7)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.66.4)\n",
            "Collecting onnx (from unstructured[pdf])\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdf2image (from unstructured[pdf])\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Collecting pdfminer.six (from unstructured[pdf])\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pikepdf (from unstructured[pdf])\n",
            "  Downloading pikepdf-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow-heif (from unstructured[pdf])\n",
            "  Downloading pillow_heif-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.2.0)\n",
            "Collecting pytesseract (from unstructured[pdf])\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting google-cloud-vision (from unstructured[pdf])\n",
            "  Downloading google_cloud_vision-3.7.2-py2.py3-none-any.whl (459 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.6/459.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting effdet (from unstructured[pdf])\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unstructured-inference==0.7.35 (from unstructured[pdf])\n",
            "  Downloading unstructured_inference-0.7.35-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unstructured.pytesseract>=0.3.12 (from unstructured[pdf])\n",
            "  Downloading unstructured.pytesseract-0.3.12-py3-none-any.whl (14 kB)\n",
            "Collecting layoutparser (from unstructured-inference==0.7.35->unstructured[pdf])\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.35->unstructured[pdf]) (0.0.9)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.35->unstructured[pdf]) (0.23.4)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.35->unstructured[pdf]) (4.8.0.76)\n",
            "Requirement already satisfied: onnxruntime>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.35->unstructured[pdf]) (1.18.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.35->unstructured[pdf]) (3.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.35->unstructured[pdf]) (2.3.0+cu121)\n",
            "Collecting timm (from unstructured-inference==0.7.35->unstructured[pdf])\n",
            "  Downloading timm-1.0.7-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.35->unstructured[pdf]) (4.41.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (9.4.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured[pdf]) (2.5)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured[pdf]) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[pdf]) (0.18.0+cu121)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[pdf]) (2.0.8)\n",
            "Collecting omegaconf>=2.0 (from effdet->unstructured[pdf])\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[pdf]) (2.11.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[pdf]) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[pdf]) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[pdf]) (3.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured[pdf]) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]) (2024.5.15)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[pdf]) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[pdf]) (42.0.8)\n",
            "Collecting Pillow>=8.0.0 (from unstructured.pytesseract>=0.3.12->unstructured[pdf])\n",
            "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from pikepdf->unstructured[pdf]) (1.2.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[pdf]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[pdf]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[pdf]) (2024.6.2)\n",
            "Requirement already satisfied: deepdiff>=6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (7.0.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (0.27.0)\n",
            "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (1.0.6)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (1.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (2.8.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (1.16.0)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from deepdiff>=6.0->unstructured-client->unstructured[pdf]) (4.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.63.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (0.14.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->unstructured[pdf])\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (6.0.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.35->unstructured[pdf]) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.35->unstructured[pdf]) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.35->unstructured[pdf]) (1.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.35->unstructured[pdf]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.35->unstructured[pdf]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.35->unstructured[pdf]) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.35->unstructured[pdf]) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.35->unstructured[pdf]) (3.1.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->unstructured-inference==0.7.35->unstructured[pdf]) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (3.15.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.35->unstructured[pdf]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->unstructured-inference==0.7.35->unstructured[pdf]) (12.5.40)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.35->unstructured[pdf]) (0.19.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference==0.7.35->unstructured[pdf]) (1.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference==0.7.35->unstructured[pdf]) (2.0.3)\n",
            "Collecting iopath (from layoutparser->unstructured-inference==0.7.35->unstructured[pdf])\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber (from layoutparser->unstructured-inference==0.7.35->unstructured[pdf])\n",
            "  Downloading pdfplumber-0.11.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.6.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.2.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.35->unstructured[pdf]) (10.0)\n",
            "Collecting portalocker (from iopath->layoutparser->unstructured-inference==0.7.35->unstructured[pdf])\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->unstructured-inference==0.7.35->unstructured[pdf]) (2.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser->unstructured-inference==0.7.35->unstructured[pdf]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser->unstructured-inference==0.7.35->unstructured[pdf]) (2024.1)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser->unstructured-inference==0.7.35->unstructured[pdf])\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.7.35->unstructured[pdf]) (1.3.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, iopath\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=9ed5604faf8afbe225360503ec7d53969f526bddd8c8c36194b2679d69182c78\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=01e083ca21a0387f09ade7b693d774bb0f874ff07812949ad46bf158394ecff6\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built antlr4-python3-runtime iopath\n",
            "Installing collected packages: antlr4-python3-runtime, pypdfium2, portalocker, Pillow, onnx, omegaconf, unstructured.pytesseract, pytesseract, pillow-heif, pikepdf, pdf2image, iopath, pdfminer.six, pdfplumber, timm, layoutparser, google-cloud-vision, unstructured-inference, effdet\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.3.0 antlr4-python3-runtime-4.9.3 effdet-0.4.1 google-cloud-vision-3.7.2 iopath-0.1.10 layoutparser-0.3.4 omegaconf-2.3.0 onnx-1.16.1 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.1 pikepdf-9.0.0 pillow-heif-0.16.0 portalocker-2.8.2 pypdfium2-4.30.0 pytesseract-0.3.10 timm-1.0.7 unstructured-inference-0.7.35 unstructured.pytesseract-0.3.12\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "ae8f45a1c84548c29fd555f0436cae80",
              "pip_warning": {
                "packages": [
                  "PIL",
                  "google",
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install \"unstructured[pdf]\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKhPCFC2UDEn",
        "outputId": "98868973-a420-4e07-feb5-ad87623267f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "zip_file_path = '/content/Book.zip'\n",
        "\n",
        "def load_docs_from_zip(zip_file_path):\n",
        "    # Extract the ZIP file contents to a temporary directory\n",
        "    temp_dir = '/content/temp_zip_extracted'\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(temp_dir)\n",
        "\n",
        "    # Use DirectoryLoader to load documents from the extracted directory\n",
        "    loader = DirectoryLoader(temp_dir)\n",
        "    documents = loader.load()\n",
        "\n",
        "    return documents\n",
        "\n",
        "documents = load_docs_from_zip(zip_file_path)\n",
        "print(len(documents))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbcyQt_lVX4c",
        "outputId": "ed568782-7477-4649-a954-273c89810af6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "610\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def split_docs(documents,chunk_size=1000,chunk_overlap=20):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "  return docs\n",
        "\n",
        "docs = split_docs(documents)\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7b09ef38fc614d4a88b714eeb2dac157",
            "0404c11714bc43bba8849fe036a0e463",
            "5209b20a7b9742a59e2935b0344c1804",
            "197d97d304aa432098af0bc8a7b0975c",
            "11383d18491147a489eafa75cea0eed2",
            "f14f1c64c0a549fea277e69b85bc7df6",
            "5a01c8718bb24071a15d8e6d906e0f6f",
            "7d6205561b4d47f9aa6225689c5f4e84",
            "6f7c3a4a0a5040f5950647a269aecd7c",
            "489620c69e0741f3a33df1367fc8620f",
            "e72fd2a6cad74b94a9bc9617bb5bbb19"
          ]
        },
        "id": "fGCA1medVbZZ",
        "outputId": "7ef8ad0c-319c-4bd1-9358-493ac5d75884"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b09ef38fc614d4a88b714eeb2dac157",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZKGu6cLKVey4"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "db = Chroma.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ooRe7ZSiVi9A"
      },
      "outputs": [],
      "source": [
        "query = \"What does chapter one the flooding smile tells\"\n",
        "matching_docs = db.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYwSfToGV7kl",
        "outputId": "f0c94781-22c8-4d7e-c1c0-ba75badbb566"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='Technique\\t1: The\\tflooding\\tsmile Don’t\\tflash\\tan\\timmediate\\tsmile\\twhen\\tyou\\tgreet\\tsomeone,\\tas\\tthough\\tanyone who\\twalked\\tinto\\tyour\\tline\\tof\\tsight\\twould\\tbe\\tthe\\tbeneficiary.\\tInstead,\\tlook\\tat the\\tother\\tperson’s\\tface\\tfor\\ta\\tsecond.\\tPause.\\tSoak\\tin\\ttheir\\tpersona.\\tThen\\tlet\\ta big,\\t warm,\\t responsive\\t smile\\t flood\\t over\\t your\\t face\\t and\\t overflow\\t into\\t your eyes.\\tIt\\twill\\tengulf\\tthe\\trecipient\\tlike\\ta\\twarm\\twave.\\tThe\\tsplit-second\\tdelay convinces\\tpeople\\tyour\\tflooding\\tsmile\\tis\\tgenuine\\tand\\tonly\\tfor\\tthem.\\n\\nLet\\t us\\t now\\t travel\\t but\\t a\\t few\\t inches\\t north\\t to\\t two\\t of\\t the\\t most\\t powerful communications\\ttools\\tyou\\tpossess,\\tyour\\teyes.\\n\\nHow\\tto\\tdetonate\\tthose\\tgrenades\\tresting\\ton\\tyour\\tnose', metadata={'source': '/content/temp_zip_extracted/Book/Leil Lowndes - How to Talk to Anyone [EnglishOnlineClub.com].pdf'})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matching_docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFXUrDPlWAIJ",
        "outputId": "e0420589-c8a7-4b04-d582-6ce2eab51ce2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Technique\t1: The\tflooding\tsmile Don’t\tflash\tan\timmediate\tsmile\twhen\tyou\tgreet\tsomeone,\tas\tthough\tanyone who\twalked\tinto\tyour\tline\tof\tsight\twould\tbe\tthe\tbeneficiary.\tInstead,\tlook\tat the\tother\tperson’s\tface\tfor\ta\tsecond.\tPause.\tSoak\tin\ttheir\tpersona.\tThen\tlet\ta big,\t warm,\t responsive\t smile\t flood\t over\t your\t face\t and\t overflow\t into\t your eyes.\tIt\twill\tengulf\tthe\trecipient\tlike\ta\twarm\twave.\tThe\tsplit-second\tdelay convinces\tpeople\tyour\tflooding\tsmile\tis\tgenuine\tand\tonly\tfor\tthem.\n",
            "\n",
            "Let\t us\t now\t travel\t but\t a\t few\t inches\t north\t to\t two\t of\t the\t most\t powerful communications\ttools\tyou\tpossess,\tyour\teyes.\n",
            "\n",
            "How\tto\tdetonate\tthose\tgrenades\tresting\ton\tyour\tnose\n"
          ]
        }
      ],
      "source": [
        "print(matching_docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "u-O4WNNBWML0"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "8NeHsYHTWcoX",
        "outputId": "b7d27cc5-84fd-4222-e2aa-e24c0e13d5f4"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> Technique\t1: The\tflooding\tsmile Don’t\tflash\tan\timmediate\tsmile\twhen\tyou\tgreet\tsomeone,\tas\tthough\tanyone who\twalked\tinto\tyour\tline\tof\tsight\twould\tbe\tthe\tbeneficiary.\tInstead,\tlook\tat the\tother\tperson’s\tface\tfor\ta\tsecond.\tPause.\tSoak\tin\ttheir\tpersona.\tThen\tlet\ta big,\t warm,\t responsive\t smile\t flood\t over\t your\t face\t and\t overflow\t into\t your eyes.\tIt\twill\tengulf\tthe\trecipient\tlike\ta\twarm\twave.\tThe\tsplit-second\tdelay convinces\tpeople\tyour\tflooding\tsmile\tis\tgenuine\tand\tonly\tfor\tthem.\n",
              "> \n",
              "> Let\t us\t now\t travel\t but\t a\t few\t inches\t north\t to\t two\t of\t the\t most\t powerful communications\ttools\tyou\tpossess,\tyour\teyes.\n",
              "> \n",
              "> How\tto\tdetonate\tthose\tgrenades\tresting\ton\tyour\tnose"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_markdown(matching_docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwmrD2gzW3ZS",
        "outputId": "0018a748-9544-4b2e-b7b9-ae7948ec6feb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(Document(page_content='Technique\\t1: The\\tflooding\\tsmile Don’t\\tflash\\tan\\timmediate\\tsmile\\twhen\\tyou\\tgreet\\tsomeone,\\tas\\tthough\\tanyone who\\twalked\\tinto\\tyour\\tline\\tof\\tsight\\twould\\tbe\\tthe\\tbeneficiary.\\tInstead,\\tlook\\tat the\\tother\\tperson’s\\tface\\tfor\\ta\\tsecond.\\tPause.\\tSoak\\tin\\ttheir\\tpersona.\\tThen\\tlet\\ta big,\\t warm,\\t responsive\\t smile\\t flood\\t over\\t your\\t face\\t and\\t overflow\\t into\\t your eyes.\\tIt\\twill\\tengulf\\tthe\\trecipient\\tlike\\ta\\twarm\\twave.\\tThe\\tsplit-second\\tdelay convinces\\tpeople\\tyour\\tflooding\\tsmile\\tis\\tgenuine\\tand\\tonly\\tfor\\tthem.\\n\\nLet\\t us\\t now\\t travel\\t but\\t a\\t few\\t inches\\t north\\t to\\t two\\t of\\t the\\t most\\t powerful communications\\ttools\\tyou\\tpossess,\\tyour\\teyes.\\n\\nHow\\tto\\tdetonate\\tthose\\tgrenades\\tresting\\ton\\tyour\\tnose', metadata={'source': '/content/temp_zip_extracted/Book/Leil Lowndes - How to Talk to Anyone [EnglishOnlineClub.com].pdf'}),\n",
              "  0.9922373294830322),\n",
              " (Document(page_content='I\\t decided\\t to\\t do\\t more\\t research\\t on\\t the\\t smile.\\t When\\t you’re\\t in\\t the\\t market\\t for shoes,\\t you\\t begin\\t to\\t look\\t at\\t everyone’s\\t feet.\\t When\\t you\\t decide\\t to\\t change\\t your hairstyle,\\t you\\t look\\t at\\t everyone’s\\t haircut.\\t Well,\\t for\\t several\\t months,\\t I\\t became\\t a steady\\tsmile\\twatcher.\\tI\\twatched\\tsmiles\\ton\\tthe\\tstreet.\\tI\\twatched\\tsmiles\\ton\\tTV.\\tI watched\\tthe\\tsmiles\\tof\\tpoliticians,\\tthe\\tclergy,\\tcorporate\\tgiants,\\tand\\tworld\\tleaders. My\\tfindings?\\tAmidst\\tthe\\tsea\\tof\\tflashing\\tteeth\\tand\\tparting\\tlips,\\tI\\tdiscovered\\tthe people\\t perceived\\t to\\t have\\t the\\t most\\t credibility\\t and\\t integrity\\t were\\t just\\t ever\\t so slower\\t to\\t smile.\\t Then,\\t when\\t they\\t did,\\t their\\t smiles\\t seemed\\t to\\t seep\\t into\\t every crevice\\t of\\t their\\t faces\\t and\\t envelop\\t them\\t like\\t a\\t slow\\t flood.\\t Thus\\t I\\t call\\t the following\\ttechnique\\tThe\\tFlooding\\tSmile.', metadata={'source': '/content/temp_zip_extracted/Book/Leil Lowndes - How to Talk to Anyone [EnglishOnlineClub.com].pdf'}),\n",
              "  1.0783302783966064)]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matching_docs = db.similarity_search_with_score(query,k=2)\n",
        "matching_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "elSLllIQXkjF",
        "outputId": "ad5e040e-90bd-43ae-8a31-1a81bac1f385"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> Technique\t1: The\tflooding\tsmile Don’t\tflash\tan\timmediate\tsmile\twhen\tyou\tgreet\tsomeone,\tas\tthough\tanyone who\twalked\tinto\tyour\tline\tof\tsight\twould\tbe\tthe\tbeneficiary.\tInstead,\tlook\tat the\tother\tperson’s\tface\tfor\ta\tsecond.\tPause.\tSoak\tin\ttheir\tpersona.\tThen\tlet\ta big,\t warm,\t responsive\t smile\t flood\t over\t your\t face\t and\t overflow\t into\t your eyes.\tIt\twill\tengulf\tthe\trecipient\tlike\ta\twarm\twave.\tThe\tsplit-second\tdelay convinces\tpeople\tyour\tflooding\tsmile\tis\tgenuine\tand\tonly\tfor\tthem.\n",
              "> \n",
              "> Let\t us\t now\t travel\t but\t a\t few\t inches\t north\t to\t two\t of\t the\t most\t powerful communications\ttools\tyou\tpossess,\tyour\teyes.\n",
              "> \n",
              "> How\tto\tdetonate\tthose\tgrenades\tresting\ton\tyour\tnose"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_markdown(matching_docs[0][0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "tvvrYy7KXtfD",
        "outputId": "cc52224a-a017-4fb8-da62-6131531ff53e"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> I\t decided\t to\t do\t more\t research\t on\t the\t smile.\t When\t you’re\t in\t the\t market\t for shoes,\t you\t begin\t to\t look\t at\t everyone’s\t feet.\t When\t you\t decide\t to\t change\t your hairstyle,\t you\t look\t at\t everyone’s\t haircut.\t Well,\t for\t several\t months,\t I\t became\t a steady\tsmile\twatcher.\tI\twatched\tsmiles\ton\tthe\tstreet.\tI\twatched\tsmiles\ton\tTV.\tI watched\tthe\tsmiles\tof\tpoliticians,\tthe\tclergy,\tcorporate\tgiants,\tand\tworld\tleaders. My\tfindings?\tAmidst\tthe\tsea\tof\tflashing\tteeth\tand\tparting\tlips,\tI\tdiscovered\tthe people\t perceived\t to\t have\t the\t most\t credibility\t and\t integrity\t were\t just\t ever\t so slower\t to\t smile.\t Then,\t when\t they\t did,\t their\t smiles\t seemed\t to\t seep\t into\t every crevice\t of\t their\t faces\t and\t envelop\t them\t like\t a\t slow\t flood.\t Thus\t I\t call\t the following\ttechnique\tThe\tFlooding\tSmile."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_markdown(matching_docs[1][0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JqYJVhQZl-pn"
      },
      "outputs": [],
      "source": [
        "persist_directory = \"chroma_db\"\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=docs, embedding=embeddings, persist_directory=persist_directory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LnR1xeNmVOm",
        "outputId": "1e40ce09-8540-4d46-e4be-0db014d8fbd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "vectordb.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pJLQs9kVmWqR"
      },
      "outputs": [],
      "source": [
        "new_db = Chroma(persist_directory=persist_directory, embedding_function=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0zuIWulmavO",
        "outputId": "4a4ef90f-b953-41b3-f0c8-50ade6fcd9b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Document(page_content='Technique\\t1: The\\tflooding\\tsmile Don’t\\tflash\\tan\\timmediate\\tsmile\\twhen\\tyou\\tgreet\\tsomeone,\\tas\\tthough\\tanyone who\\twalked\\tinto\\tyour\\tline\\tof\\tsight\\twould\\tbe\\tthe\\tbeneficiary.\\tInstead,\\tlook\\tat the\\tother\\tperson’s\\tface\\tfor\\ta\\tsecond.\\tPause.\\tSoak\\tin\\ttheir\\tpersona.\\tThen\\tlet\\ta big,\\t warm,\\t responsive\\t smile\\t flood\\t over\\t your\\t face\\t and\\t overflow\\t into\\t your eyes.\\tIt\\twill\\tengulf\\tthe\\trecipient\\tlike\\ta\\twarm\\twave.\\tThe\\tsplit-second\\tdelay convinces\\tpeople\\tyour\\tflooding\\tsmile\\tis\\tgenuine\\tand\\tonly\\tfor\\tthem.\\n\\nLet\\t us\\t now\\t travel\\t but\\t a\\t few\\t inches\\t north\\t to\\t two\\t of\\t the\\t most\\t powerful communications\\ttools\\tyou\\tpossess,\\tyour\\teyes.\\n\\nHow\\tto\\tdetonate\\tthose\\tgrenades\\tresting\\ton\\tyour\\tnose', metadata={'source': '/content/temp_zip_extracted/Book/Leil Lowndes - How to Talk to Anyone [EnglishOnlineClub.com].pdf'}),\n",
              " 0.9922373294830322)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matching_docs = new_db.similarity_search_with_score(query)\n",
        "matching_docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dfRa5DiZmjdR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['Google_API_KEY'] ='Google_API_KEY'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "iE0Opil2mvaz"
      },
      "outputs": [],
      "source": [
        "genai.configure(api_key=os.environ['Google_API_KEY'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "6-cs9GsbmxX5"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "tsBsvvUIm_Um"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key='Google_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2sKlDS5gnID3"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5ErYWd0nXbdT"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azUJlQ1_c2qo"
      },
      "source": [
        "ANSWERS QUERY BASED ON TEXT USING LOAD_QA_CHAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "sopU-evDQbz4"
      },
      "outputs": [],
      "source": [
        "# Define a prompt template\n",
        "prompt_template = \"\"\"\n",
        "You are a helpful assistant. Use the following context to answer the question.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template)\n",
        "\n",
        "# Load the QA chain using the prompt template\n",
        "qa_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=prompt,verbose='true')\n",
        "def fncc(query):\n",
        "    matching_docs = new_db.similarity_search(query)\n",
        "    text=matching_docs\n",
        "    return qa_chain.run({\"input_documents\":text, \"question\": query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "zaaHW_bdQePV",
        "outputId": "b4f8a327-6647-447a-b57d-89f0c6ad67db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a helpful assistant. Use the following context to answer the question.\n",
            "\n",
            "Context:\n",
            "Technique\t1: The\tflooding\tsmile Don’t\tflash\tan\timmediate\tsmile\twhen\tyou\tgreet\tsomeone,\tas\tthough\tanyone who\twalked\tinto\tyour\tline\tof\tsight\twould\tbe\tthe\tbeneficiary.\tInstead,\tlook\tat the\tother\tperson’s\tface\tfor\ta\tsecond.\tPause.\tSoak\tin\ttheir\tpersona.\tThen\tlet\ta big,\t warm,\t responsive\t smile\t flood\t over\t your\t face\t and\t overflow\t into\t your eyes.\tIt\twill\tengulf\tthe\trecipient\tlike\ta\twarm\twave.\tThe\tsplit-second\tdelay convinces\tpeople\tyour\tflooding\tsmile\tis\tgenuine\tand\tonly\tfor\tthem.\n",
            "\n",
            "Let\t us\t now\t travel\t but\t a\t few\t inches\t north\t to\t two\t of\t the\t most\t powerful communications\ttools\tyou\tpossess,\tyour\teyes.\n",
            "\n",
            "How\tto\tdetonate\tthose\tgrenades\tresting\ton\tyour\tnose\n",
            "\n",
            "I\t decided\t to\t do\t more\t research\t on\t the\t smile.\t When\t you’re\t in\t the\t market\t for shoes,\t you\t begin\t to\t look\t at\t everyone’s\t feet.\t When\t you\t decide\t to\t change\t your hairstyle,\t you\t look\t at\t everyone’s\t haircut.\t Well,\t for\t several\t months,\t I\t became\t a steady\tsmile\twatcher.\tI\twatched\tsmiles\ton\tthe\tstreet.\tI\twatched\tsmiles\ton\tTV.\tI watched\tthe\tsmiles\tof\tpoliticians,\tthe\tclergy,\tcorporate\tgiants,\tand\tworld\tleaders. My\tfindings?\tAmidst\tthe\tsea\tof\tflashing\tteeth\tand\tparting\tlips,\tI\tdiscovered\tthe people\t perceived\t to\t have\t the\t most\t credibility\t and\t integrity\t were\t just\t ever\t so slower\t to\t smile.\t Then,\t when\t they\t did,\t their\t smiles\t seemed\t to\t seep\t into\t every crevice\t of\t their\t faces\t and\t envelop\t them\t like\t a\t slow\t flood.\t Thus\t I\t call\t the following\ttechnique\tThe\tFlooding\tSmile.\n",
            "\n",
            "As\ta\tyoung\tgirl,\tI\twrote\tnovels\tin\tmy\tmind\tabout\tmy\tlife.\t‘Leil,\tsquinting\ther eyes\t against\t the\t torrential\t downpour,\t bravely\t reached\t out\t the\t window\t into\t the icy\tstorm\tto\tpull\tthe\tshutters\ttight\tand\tkeep\tthe\tfamily\tsafe\tfrom\tthe\tapproaching hurricane.’\tBig\tdeal\t–\tMama\tasked\tme\tto\tclose\tthe\twindows\twhen\tit\tstarted\tto rain.\t Still,\t marching\t toward\t the\t open\t window,\t I\t fancied\t myself\t the\t family’s brave\tsaviour.\n",
            "\n",
            "You\t don’t\t need\t to\t be\t quite\t so\t melodramatic\t in\t your\t self-image,\t but\t at\t least\n",
            "\n",
            "punch\tup\tyour\tlife\tto\tsound\tinteresting\tand\tdedicated.\n",
            "\n",
            "Before\twalking\tthrough\tany\tdoor\t–\tthe\tdoor\tto\tyour\toffice,\ta\tparty,\ta\tmeeting, even\tyour\tkitchen\t–\tpicture\ta\tleather\tbit\thanging\tby\ta\tcable\tfrom\tthe\tframe.\tIt\tis swinging\t just\t an\t inch\t higher\t than\t your\t head.\t As\t you\t pass\t through\t the\t door, throw\tyour\thead\tback\tand\tchomp\ton\tthe\timaginary\tdental\tgrip\twhich\tfirst\tpulls your\tcheeks\tback\tinto\ta\tsmile,\tand\tthen\tlifts\tyou\tup.\tAs\tyou\tascend\thigh\tabove the\t gasping\t crowd,\t your\t body\t is\t stretched\t into\t perfect\t alignment\t –\t head\t high, shoulders\tback,\ttorso\tout\tof\thips,\tfeet\tweightless.\tAt\tthe\tzenith\tof\tthe\ttent,\tyou spin\tlike\ta\tgraceful\ttop\tto\tthe\tamazement\tand\tadmiration\tof\tthe\tcrowd\tcraning their\tnecks\tto\twatch\tyou.\tNow\tyou\tlook\tlike\ta\tSomebody.\n",
            "\n",
            "Question: What does chapter one the flooding smile tells?\n",
            "\n",
            "Answer:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Chapter one of \"The Flooding Smile\" discusses the importance of genuine and delayed smiles in creating a positive and credible impression.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fncc(\"What does chapter one the flooding smile tells?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bbdDOnFc9uZ"
      },
      "source": [
        "ANSWERS QUERY BASED ON DOCUMENT USING LLMCHAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTg32eY2FhRN",
        "outputId": "d83bfaf9-ca25-4ccc-99e6-db5820df4940"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "prompt_template = \"\"\"\n",
        "You are a helpful assistant. Use the following context to answer the question.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Load the QA chain with the prompt template\n",
        "prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template)\n",
        "\n",
        "# Load the QA chain\n",
        "qa_chain = LLMChain(llm=llm, prompt=prompt,verbose='true')\n",
        "# Prepare input for the chain\n",
        "# context = \"\\n\\n\".join([doc.page_content for doc in matching_docs])\n",
        "# input_documents = [{\"context\": context, \"question\": query}]\n",
        "def fnc(query):\n",
        "    matching_docs = new_db.similarity_search(query)\n",
        "    text=matching_docs[0].page_content\n",
        "# Run the chain\n",
        "    answer = qa_chain.run({\"context\":text, \"question\": query})\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "aUE7jqVXKcqE",
        "outputId": "2d72df72-8503-42b3-f7ce-537347b6bc84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a helpful assistant. Use the following context to answer the question.\n",
            "\n",
            "Context:\n",
            "Technique\t1: The\tflooding\tsmile Don’t\tflash\tan\timmediate\tsmile\twhen\tyou\tgreet\tsomeone,\tas\tthough\tanyone who\twalked\tinto\tyour\tline\tof\tsight\twould\tbe\tthe\tbeneficiary.\tInstead,\tlook\tat the\tother\tperson’s\tface\tfor\ta\tsecond.\tPause.\tSoak\tin\ttheir\tpersona.\tThen\tlet\ta big,\t warm,\t responsive\t smile\t flood\t over\t your\t face\t and\t overflow\t into\t your eyes.\tIt\twill\tengulf\tthe\trecipient\tlike\ta\twarm\twave.\tThe\tsplit-second\tdelay convinces\tpeople\tyour\tflooding\tsmile\tis\tgenuine\tand\tonly\tfor\tthem.\n",
            "\n",
            "Let\t us\t now\t travel\t but\t a\t few\t inches\t north\t to\t two\t of\t the\t most\t powerful communications\ttools\tyou\tpossess,\tyour\teyes.\n",
            "\n",
            "How\tto\tdetonate\tthose\tgrenades\tresting\ton\tyour\tnose\n",
            "\n",
            "Question: What does chapter one the flooding smile tells?\n",
            "\n",
            "Answer:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Chapter one, \"The Flooding Smile,\" describes a technique for creating a genuine and engaging smile that makes the recipient feel valued and appreciated. It involves looking at the other person\\'s face for a second, pausing, and then letting a big, warm smile flood over your face and into your eyes. The split-second delay convinces people that your smile is genuine and only for them.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fnc(\"What does chapter one the flooding smile tells?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkeAZZalY4or",
        "outputId": "1a541558-8846-4cac-e859-d0fff4e23d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement google-gemini (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for google-gemini\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# !pip install google-gemini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etp9G_W7dHGl"
      },
      "source": [
        "ANSWERS QUERY BASED ON CHAT HISTORY BUT DOES NOT REFINE QUERY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "l-yPNU4paxkG"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "prompt_template = \"\"\"\n",
        "You are a helpful assistant. Use the following context to answer the question using chat_history whenever required.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Chat History:\n",
        "{chat_history}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Load the QA chain with the prompt template\n",
        "prompt = PromptTemplate(input_variables=[\"context\", \"question\",\"chat_history\"], template=prompt_template)\n",
        "\n",
        "# Load the QA chain\n",
        "qa_chain = LLMChain(llm=llm, prompt=prompt,verbose='true')\n",
        "# Prepare input for the chain\n",
        "# context = \"\\n\\n\".join([doc.page_content for doc in matching_docs])\n",
        "# input_documents = [{\"context\": context, \"question\": query}]\n",
        "prev=[]\n",
        "def fnc(query):\n",
        "    matching_docs = new_db.similarity_search(query)\n",
        "    text=matching_docs[0].page_content\n",
        "# Run the chain\n",
        "    print(text)\n",
        "    answer = qa_chain.run({\"context\":text, \"question\": query,\"chat_history\":prev})\n",
        "    prev.append(answer)\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TkjB6SqblX2",
        "outputId": "840562b9-76ee-4861-bc5e-ff364a151b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a question: what is flooding smile\n",
            "Technique\t1: The\tflooding\tsmile Don’t\tflash\tan\timmediate\tsmile\twhen\tyou\tgreet\tsomeone,\tas\tthough\tanyone who\twalked\tinto\tyour\tline\tof\tsight\twould\tbe\tthe\tbeneficiary.\tInstead,\tlook\tat the\tother\tperson’s\tface\tfor\ta\tsecond.\tPause.\tSoak\tin\ttheir\tpersona.\tThen\tlet\ta big,\t warm,\t responsive\t smile\t flood\t over\t your\t face\t and\t overflow\t into\t your eyes.\tIt\twill\tengulf\tthe\trecipient\tlike\ta\twarm\twave.\tThe\tsplit-second\tdelay convinces\tpeople\tyour\tflooding\tsmile\tis\tgenuine\tand\tonly\tfor\tthem.\n",
            "\n",
            "Let\t us\t now\t travel\t but\t a\t few\t inches\t north\t to\t two\t of\t the\t most\t powerful communications\ttools\tyou\tpossess,\tyour\teyes.\n",
            "\n",
            "How\tto\tdetonate\tthose\tgrenades\tresting\ton\tyour\tnose\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a helpful assistant. Use the following context to answer the question using chat_history whenever required.\n",
            "\n",
            "Context:\n",
            "Technique\t1: The\tflooding\tsmile Don’t\tflash\tan\timmediate\tsmile\twhen\tyou\tgreet\tsomeone,\tas\tthough\tanyone who\twalked\tinto\tyour\tline\tof\tsight\twould\tbe\tthe\tbeneficiary.\tInstead,\tlook\tat the\tother\tperson’s\tface\tfor\ta\tsecond.\tPause.\tSoak\tin\ttheir\tpersona.\tThen\tlet\ta big,\t warm,\t responsive\t smile\t flood\t over\t your\t face\t and\t overflow\t into\t your eyes.\tIt\twill\tengulf\tthe\trecipient\tlike\ta\twarm\twave.\tThe\tsplit-second\tdelay convinces\tpeople\tyour\tflooding\tsmile\tis\tgenuine\tand\tonly\tfor\tthem.\n",
            "\n",
            "Let\t us\t now\t travel\t but\t a\t few\t inches\t north\t to\t two\t of\t the\t most\t powerful communications\ttools\tyou\tpossess,\tyour\teyes.\n",
            "\n",
            "How\tto\tdetonate\tthose\tgrenades\tresting\ton\tyour\tnose\n",
            "\n",
            "Question: what is flooding smile\n",
            "\n",
            "Chat History:\n",
            "[]\n",
            "\n",
            "Answer:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "A flooding smile is a technique where you don't flash an immediate smile when you greet someone, but instead look at the other person's face for a second, pause, and then let a big, warm, responsive smile flood over your face and overflow into your eyes.\n",
            "\n",
            "Enter a question: what sre benifits of flooding smile\n",
            "Technique\t1: The\tflooding\tsmile Don’t\tflash\tan\timmediate\tsmile\twhen\tyou\tgreet\tsomeone,\tas\tthough\tanyone who\twalked\tinto\tyour\tline\tof\tsight\twould\tbe\tthe\tbeneficiary.\tInstead,\tlook\tat the\tother\tperson’s\tface\tfor\ta\tsecond.\tPause.\tSoak\tin\ttheir\tpersona.\tThen\tlet\ta big,\t warm,\t responsive\t smile\t flood\t over\t your\t face\t and\t overflow\t into\t your eyes.\tIt\twill\tengulf\tthe\trecipient\tlike\ta\twarm\twave.\tThe\tsplit-second\tdelay convinces\tpeople\tyour\tflooding\tsmile\tis\tgenuine\tand\tonly\tfor\tthem.\n",
            "\n",
            "Let\t us\t now\t travel\t but\t a\t few\t inches\t north\t to\t two\t of\t the\t most\t powerful communications\ttools\tyou\tpossess,\tyour\teyes.\n",
            "\n",
            "How\tto\tdetonate\tthose\tgrenades\tresting\ton\tyour\tnose\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a helpful assistant. Use the following context to answer the question using chat_history whenever required.\n",
            "\n",
            "Context:\n",
            "Technique\t1: The\tflooding\tsmile Don’t\tflash\tan\timmediate\tsmile\twhen\tyou\tgreet\tsomeone,\tas\tthough\tanyone who\twalked\tinto\tyour\tline\tof\tsight\twould\tbe\tthe\tbeneficiary.\tInstead,\tlook\tat the\tother\tperson’s\tface\tfor\ta\tsecond.\tPause.\tSoak\tin\ttheir\tpersona.\tThen\tlet\ta big,\t warm,\t responsive\t smile\t flood\t over\t your\t face\t and\t overflow\t into\t your eyes.\tIt\twill\tengulf\tthe\trecipient\tlike\ta\twarm\twave.\tThe\tsplit-second\tdelay convinces\tpeople\tyour\tflooding\tsmile\tis\tgenuine\tand\tonly\tfor\tthem.\n",
            "\n",
            "Let\t us\t now\t travel\t but\t a\t few\t inches\t north\t to\t two\t of\t the\t most\t powerful communications\ttools\tyou\tpossess,\tyour\teyes.\n",
            "\n",
            "How\tto\tdetonate\tthose\tgrenades\tresting\ton\tyour\tnose\n",
            "\n",
            "Question: what sre benifits of flooding smile\n",
            "\n",
            "Chat History:\n",
            "[\"A flooding smile is a technique where you don't flash an immediate smile when you greet someone, but instead look at the other person's face for a second, pause, and then let a big, warm, responsive smile flood over your face and overflow into your eyes.\"]\n",
            "\n",
            "Answer:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "A flooding smile has several benefits:\n",
            "\n",
            "- It convinces people that your smile is genuine and only for them.\n",
            "- It makes you appear more approachable and friendly.\n",
            "- It can help to build rapport and trust.\n",
            "- It can make you more persuasive.\n",
            "- It can help to reduce stress and anxiety.\n",
            "\n",
            "Enter a question: exit\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    query = input(\"Enter a question: \")\n",
        "    if query == \"exit\":\n",
        "        break\n",
        "    print(fnc(query))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca61lLZfdUck"
      },
      "source": [
        "CODE TO GET REFINED QUERY(THAT TRIES TO RELATE WITH PREVIOUS RESPONSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "NzcPv7uMN3gH"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Install the Google AI Python SDK\n",
        "\n",
        "$ pip install google-generativeai\n",
        "\n",
        "See the getting started guide for more information:\n",
        "https://ai.google.dev/gemini-api/docs/get-started/python\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 64,\n",
        "  \"max_output_tokens\": 8192,\n",
        "  # \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-flash\",\n",
        "  generation_config=generation_config,\n",
        "  system_instruction=\"Your name is Sam, given the following user query and conversation log, formulate a question that would be the most relevant to provide the user with an answer from a knowledge base.\\\\n\\\\nCONVERSATION LOG: \\\\n{conversation}\\\\n\\\\nQuery: {query}\\\\n\\\\nRefined Query:\",\n",
        ")\n",
        "\n",
        "chat_session = model.start_chat(\n",
        "  history=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [\n",
        "        \"hi\",\n",
        "      ],\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"model\",\n",
        "      \"parts\": [\n",
        "        \"Refined Query:  What can I help you with today? \\n\",\n",
        "      ],\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "\n",
        "# response = chat_session.send_message(\"INSERT_INPUT_HERE\")\n",
        "\n",
        "# print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "q4cKdSoAO7oZ"
      },
      "outputs": [],
      "source": [
        "response=chat_session.send_message(\"Conversation Log: The benefits of a flooding smile include:\\nIt conveys genuineness and sincerity.\\nIt makes the recipient feel special.\\nIt helps to build rapport and trust.\\nIt can defuse tension and create a more positive atmosphere. Query: Explain Second Benefit\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QcUeBp3dUBMW",
        "outputId": "f0d411f7-382d-410c-d1a4-78bc548018d2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Refined Query: What does a flooding smile do to make the recipient feel special? \\n'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4uvjEMfdnBB"
      },
      "source": [
        "SIMPLE FUNCTION TO GET REFINED QUERY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "j8H1zxfHVb2k"
      },
      "outputs": [],
      "source": [
        "def query_refiner(conversation,query):\n",
        "\n",
        "    generation_config = {\n",
        "    \"temperature\": 1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 64,\n",
        "    \"max_output_tokens\": 8192,\n",
        "     }\n",
        "\n",
        "    model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    generation_config=generation_config,\n",
        "    system_instruction=f\"Your name is Sam, given the following user query and conversation log, formulate a question that would be the most relevant to provide the user with an answer from a knowledge base.\\\\n\\\\nCONVERSATION LOG: \\\\n{conversation}\\\\n\\\\nQuery: {query}\\\\n\\\\nRefined Query:\",\n",
        "    )\n",
        "    chat_session = model.start_chat(\n",
        "    history=[])\n",
        "    response=chat_session.send_message(\"Conversation Log:{conversation} Query:{query}\")\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "JxdlC8piW2Zj"
      },
      "outputs": [],
      "source": [
        "text=\"The benefits of a flooding smile include:\\nIt conveys genuineness and sincerity.\\nIt makes the recipient feel special.\\nIt helps to build rapport and trust.\\nIt can defuse tension and create a more positive atmosphere.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "diRHMPoXXTkE"
      },
      "outputs": [],
      "source": [
        "refined_query=query_refiner(text,\"Explain Second Benefit\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DofeYfsryFlw",
        "outputId": "8febd2b3-dab1-46e6-c3e8-06872b03c1dd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Refined Query: What is the second benefit of a flooding smile? \\n'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "refined_query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCuS0qpEdtKQ"
      },
      "source": [
        "IMPLEMENTING CHAIN THAT ANSWERS QUERY BASED ON DOCUMENT AS WELL AS PREVIOUS RESPONSE USING REFINED QUERY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "cz2PrfGZV_Uc"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "prompt_template = \"\"\"\n",
        "You are a helpful assistant. Use the following context to answer the question.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Load the QA chain with the prompt template\n",
        "prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template)\n",
        "\n",
        "# Load the QA chain\n",
        "qa_chain = LLMChain(llm=llm, prompt=prompt,verbose='true')\n",
        "def fnc(query,prev):\n",
        "    matching_docs = new_db.similarity_search(query)\n",
        "    text=matching_docs[0].page_content\n",
        "    combined_prev = \"\\n\\n\".join(prev)\n",
        "    full_context = f\"{combined_prev}\\n\\n{text}\"\n",
        "    # print(full_context)\n",
        "    refined=query_refiner(full_context,query)\n",
        "\n",
        "    answer = qa_chain.run({\"context\":full_context, \"question\": refined})\n",
        "    prev.append(f\"Q: {query}\\nA: {answer}\\n\")\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hVQ38Bbb6gS",
        "outputId": "5f7c2b22-3c67-48b8-ed13-0bb8e9850740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a question: what is flooding smile\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a helpful assistant. Use the following context to answer the question.\n",
            "\n",
            "Context:\n",
            "\n",
            "\n",
            "Technique\t1: The\tflooding\tsmile Don’t\tflash\tan\timmediate\tsmile\twhen\tyou\tgreet\tsomeone,\tas\tthough\tanyone who\twalked\tinto\tyour\tline\tof\tsight\twould\tbe\tthe\tbeneficiary.\tInstead,\tlook\tat the\tother\tperson’s\tface\tfor\ta\tsecond.\tPause.\tSoak\tin\ttheir\tpersona.\tThen\tlet\ta big,\t warm,\t responsive\t smile\t flood\t over\t your\t face\t and\t overflow\t into\t your eyes.\tIt\twill\tengulf\tthe\trecipient\tlike\ta\twarm\twave.\tThe\tsplit-second\tdelay convinces\tpeople\tyour\tflooding\tsmile\tis\tgenuine\tand\tonly\tfor\tthem.\n",
            "\n",
            "Let\t us\t now\t travel\t but\t a\t few\t inches\t north\t to\t two\t of\t the\t most\t powerful communications\ttools\tyou\tpossess,\tyour\teyes.\n",
            "\n",
            "How\tto\tdetonate\tthose\tgrenades\tresting\ton\tyour\tnose\n",
            "\n",
            "Question: Refined Query: What is the flooding smile technique in communication? \n",
            "\n",
            "\n",
            "Answer:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The flooding smile technique is a communication technique where you pause and look at the other person's face for a second before smiling. This split-second delay convinces people that your flooding smile is genuine and only for them.\n",
            "\n",
            "Enter a question: what are benefits of flooding smile\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a helpful assistant. Use the following context to answer the question.\n",
            "\n",
            "Context:\n",
            "Q: what is flooding smile\n",
            "A: The flooding smile technique is a communication technique where you pause and look at the other person's face for a second before smiling. This split-second delay convinces people that your flooding smile is genuine and only for them.\n",
            "\n",
            "\n",
            "Technique\t1: The\tflooding\tsmile Don’t\tflash\tan\timmediate\tsmile\twhen\tyou\tgreet\tsomeone,\tas\tthough\tanyone who\twalked\tinto\tyour\tline\tof\tsight\twould\tbe\tthe\tbeneficiary.\tInstead,\tlook\tat the\tother\tperson’s\tface\tfor\ta\tsecond.\tPause.\tSoak\tin\ttheir\tpersona.\tThen\tlet\ta big,\t warm,\t responsive\t smile\t flood\t over\t your\t face\t and\t overflow\t into\t your eyes.\tIt\twill\tengulf\tthe\trecipient\tlike\ta\twarm\twave.\tThe\tsplit-second\tdelay convinces\tpeople\tyour\tflooding\tsmile\tis\tgenuine\tand\tonly\tfor\tthem.\n",
            "\n",
            "Let\t us\t now\t travel\t but\t a\t few\t inches\t north\t to\t two\t of\t the\t most\t powerful communications\ttools\tyou\tpossess,\tyour\teyes.\n",
            "\n",
            "How\tto\tdetonate\tthose\tgrenades\tresting\ton\tyour\tnose\n",
            "\n",
            "Question: Refined Query: What are the benefits of using the flooding smile technique in communication? \n",
            "\n",
            "\n",
            "Answer:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The benefits of using the flooding smile technique in communication include:\n",
            "\n",
            "-  Convincing people that your smile is genuine and only for them\n",
            "- Overflow into your eyes\n",
            "- Engulf the recipient like a warm wave\n",
            "\n",
            "Enter a question: explain second benefit you mentioned\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a helpful assistant. Use the following context to answer the question.\n",
            "\n",
            "Context:\n",
            "Q: what is flooding smile\n",
            "A: The flooding smile technique is a communication technique where you pause and look at the other person's face for a second before smiling. This split-second delay convinces people that your flooding smile is genuine and only for them.\n",
            "\n",
            "\n",
            "Q: what are benefits of flooding smile\n",
            "A: The benefits of using the flooding smile technique in communication include:\n",
            "\n",
            "-  Convincing people that your smile is genuine and only for them\n",
            "- Overflow into your eyes\n",
            "- Engulf the recipient like a warm wave\n",
            "\n",
            "\n",
            "Top\t salespeople\t talk\t extensively\t of\t the\t ‘benefit\t statement.’\t They\t know,\t when talking\twith\ta\tpotential\tclient,\tthey\tshould\topen\ttheir\tconversation\twith\ta\tbenefit statement.\tWhen\tmy\tcolleague\tBrian\tmakes\tcold\tcalls,\tinstead\tof\tsaying\t‘Hello, my\tname\tis\tBrian\tTracy.\tI’m\ta\tsales\ttrainer,’\the\tsays,\t‘Hello,\tmy\tname\tis\tBrian Tracy\tfrom\tthe\tInstitute\tfor\tExecutive\tDevelopment.\tWould\tyou\tbe\tinterested\tin a\t proven\t method\t that\t can\t increase\t your\t sales\t from\t 20\t to\t 30\t per\t cent\t over\t the next\t twelve\t months?’\t That\t is\t his\t benefit\t statement.\t He\t highlights\t the\t specific benefits\tof\twhat\the\thas\tto\toffer\tto\this\tprospect.\n",
            "\n",
            "Question: Refined Query: What does it mean for a smile to \"overflow into your eyes\" in the context of the flooding smile technique? \n",
            "\n",
            "\n",
            "Answer:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The text does not mention anything about a smile \"overflowing into your eyes\" in the context of the flooding smile technique.\n",
            "\n",
            "Enter a question: what is big baby pivot\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a helpful assistant. Use the following context to answer the question.\n",
            "\n",
            "Context:\n",
            "Q: what is flooding smile\n",
            "A: The flooding smile technique is a communication technique where you pause and look at the other person's face for a second before smiling. This split-second delay convinces people that your flooding smile is genuine and only for them.\n",
            "\n",
            "\n",
            "Q: what are benefits of flooding smile\n",
            "A: The benefits of using the flooding smile technique in communication include:\n",
            "\n",
            "-  Convincing people that your smile is genuine and only for them\n",
            "- Overflow into your eyes\n",
            "- Engulf the recipient like a warm wave\n",
            "\n",
            "\n",
            "Q: explain second benefit you mentioned\n",
            "A: The text does not mention anything about a smile \"overflowing into your eyes\" in the context of the flooding smile technique.\n",
            "\n",
            "\n",
            "After\ta\tfew\tmoments,\tI\texcused\tmyself.\tNeither\tnoticed\tmy\tdeparture\tbecause they\twere\tin\tanimated\tconversation.\tThe\tlast\tglimpse\tI\thad\tof\tmy\tfriend\tat\tthe party\twas\ther\tfloating\tout\tthe\tdoor\ton\tthe\tarm\tof\ther\tnew\tfriend.\n",
            "\n",
            "Just\tthen\tthe\ttechnique\tI\tcall\tthe\tBig-Baby\tPivot\twas\tborn.\tIt\tis\ta\tskill\tthat\twill help\t you\t win\t whatever\t your\t heart\t desires\t from\t whatever\t type\t of\t beasts\t you encounter\tin\tthe\tsocial\tor\tcorporate\tjungle.\n",
            "\n",
            "Technique\t5: The\tbig-baby\tpivot Give\teveryone\tyou\tmeet\tthe\tBig-Baby\tPivot.\tThe\tinstant\tthe\ttwo\tof\tyou\tare introduced,\treward\tyour\tnew\tacquaintance.\tGive\tthe\twarm\tsmile,\tthe\ttotal- body\t turn,\t and\t the\t undivided\t attention\t you\t would\t give\t a\t tiny\t tyke\t who crawled\tup\tto\tyour\tfeet,\tturned\ta\tprecious\tface\tup\tto\tyours,\tand\tbeamed\ta big\ttoothless\tgrin.\tPivoting\t100\tper\tcent\ttoward\tNew\tPerson\tshouts\t‘I\tthink you\tare\tvery,\tvery\tspecial.’\n",
            "\n",
            "Question: Refined Query: What is the Big-Baby Pivot technique and how does it work? \n",
            "\n",
            "\n",
            "Answer:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The Big-Baby Pivot technique is a communication technique where you reward someone you meet with a warm smile, total-body turn, and undivided attention, as if they were a tiny child who had just crawled up to you and beamed a big toothless grin. This technique conveys that you think the person is very special and can help you win their favor in social or corporate settings.\n",
            "\n",
            "Enter a question: how to apply it in real life\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a helpful assistant. Use the following context to answer the question.\n",
            "\n",
            "Context:\n",
            "Q: what is flooding smile\n",
            "A: The flooding smile technique is a communication technique where you pause and look at the other person's face for a second before smiling. This split-second delay convinces people that your flooding smile is genuine and only for them.\n",
            "\n",
            "\n",
            "Q: what are benefits of flooding smile\n",
            "A: The benefits of using the flooding smile technique in communication include:\n",
            "\n",
            "-  Convincing people that your smile is genuine and only for them\n",
            "- Overflow into your eyes\n",
            "- Engulf the recipient like a warm wave\n",
            "\n",
            "\n",
            "Q: explain second benefit you mentioned\n",
            "A: The text does not mention anything about a smile \"overflowing into your eyes\" in the context of the flooding smile technique.\n",
            "\n",
            "\n",
            "Q: what is big baby pivot\n",
            "A: The Big-Baby Pivot technique is a communication technique where you reward someone you meet with a warm smile, total-body turn, and undivided attention, as if they were a tiny child who had just crawled up to you and beamed a big toothless grin. This technique conveys that you think the person is very special and can help you win their favor in social or corporate settings.\n",
            "\n",
            "\n",
            "Technique\t1: The\tflooding\tsmile Don’t\tflash\tan\timmediate\tsmile\twhen\tyou\tgreet\tsomeone,\tas\tthough\tanyone who\twalked\tinto\tyour\tline\tof\tsight\twould\tbe\tthe\tbeneficiary.\tInstead,\tlook\tat the\tother\tperson’s\tface\tfor\ta\tsecond.\tPause.\tSoak\tin\ttheir\tpersona.\tThen\tlet\ta big,\t warm,\t responsive\t smile\t flood\t over\t your\t face\t and\t overflow\t into\t your eyes.\tIt\twill\tengulf\tthe\trecipient\tlike\ta\twarm\twave.\tThe\tsplit-second\tdelay convinces\tpeople\tyour\tflooding\tsmile\tis\tgenuine\tand\tonly\tfor\tthem.\n",
            "\n",
            "Let\t us\t now\t travel\t but\t a\t few\t inches\t north\t to\t two\t of\t the\t most\t powerful communications\ttools\tyou\tpossess,\tyour\teyes.\n",
            "\n",
            "How\tto\tdetonate\tthose\tgrenades\tresting\ton\tyour\tnose\n",
            "\n",
            "Question: Refined Query: How can I apply the flooding smile technique in real-life situations? \n",
            "\n",
            "\n",
            "Answer:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The context does not provide any examples of how to apply the flooding smile technique in real-life situations.\n",
            "\n",
            "Enter a question: exit\n"
          ]
        }
      ],
      "source": [
        "prev=[]\n",
        "while True:\n",
        "    query = input(\"Enter a question: \")\n",
        "    if query == \"exit\":\n",
        "        break\n",
        "    print(fnc(query,prev))\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0404c11714bc43bba8849fe036a0e463": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f14f1c64c0a549fea277e69b85bc7df6",
            "placeholder": "​",
            "style": "IPY_MODEL_5a01c8718bb24071a15d8e6d906e0f6f",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "11383d18491147a489eafa75cea0eed2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "197d97d304aa432098af0bc8a7b0975c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_489620c69e0741f3a33df1367fc8620f",
            "placeholder": "​",
            "style": "IPY_MODEL_e72fd2a6cad74b94a9bc9617bb5bbb19",
            "value": " 190/190 [00:00&lt;00:00, 8.83kB/s]"
          }
        },
        "489620c69e0741f3a33df1367fc8620f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5209b20a7b9742a59e2935b0344c1804": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d6205561b4d47f9aa6225689c5f4e84",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f7c3a4a0a5040f5950647a269aecd7c",
            "value": 190
          }
        },
        "5a01c8718bb24071a15d8e6d906e0f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f7c3a4a0a5040f5950647a269aecd7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b09ef38fc614d4a88b714eeb2dac157": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0404c11714bc43bba8849fe036a0e463",
              "IPY_MODEL_5209b20a7b9742a59e2935b0344c1804",
              "IPY_MODEL_197d97d304aa432098af0bc8a7b0975c"
            ],
            "layout": "IPY_MODEL_11383d18491147a489eafa75cea0eed2"
          }
        },
        "7d6205561b4d47f9aa6225689c5f4e84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e72fd2a6cad74b94a9bc9617bb5bbb19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f14f1c64c0a549fea277e69b85bc7df6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
